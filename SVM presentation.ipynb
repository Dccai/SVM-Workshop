{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec4554e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Welcome to My SVM Workshop\n",
    "<img src=\"data:image/jpeg;base64,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\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17936131",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is a Support Vector Machine?\n",
    "1. The Support Vector Machine is a supervised machine learning algorithm that draws decision boundaries between data points of different classes.\n",
    "2. SVM creates a decision equation through its training data, meaning that you only need to plug in values to make predictions after you are done training.\n",
    "## Why not use K-nearest Neighbours instead?\n",
    "K-nearest Neighbours has to compare the distance between the prediction data with all the training data every time you want to make a new prediction, meaning the computation time might be higher if you want to make predictions for huge datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62030f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Explaining the Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc07ef60",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The point of SVM is to create a decision boundary through support vectors that separates two different classes, which is shown by the dotted boundary line.\n",
    "\n",
    "<img src=\"https://images.spiceworks.com/wp-content/uploads/2022/09/02134804/Diagram-depicting-SVM-example-with-hyperplane-for-classification-problem.jpg\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38469ed8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Imagine running a vector perpendicular through the decision boundary\n",
    "\n",
    "<img src=\"https://editor.analyticsvidhya.com/uploads/885076.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a4503e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### That vector is $w$, and it tells how far away a data point is from the decision boundary\n",
    "\n",
    "### Assuming $x$, which is a data point, as a vector, we can find the magnitude of the projection of $x$ onto $w$, using the formula $$\\left\\lVert \\text{proj}_{\\mathbf{W}}(\\mathbf{X}) \\right\\rVert = \\frac{\\mathbf{X} \\cdot \\mathbf{W}}{|\\mathbf{W}|} \n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1969843",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### This means that we can figure out if a point is on one side of the decision boundary by seeing if the magnitude of its projection unto vector $w$ is greater or less than the distance of vector $w$ from origin to decision boundary \n",
    "<img width=\"400\" src=\"https://miro.medium.com/v2/resize:fit:1400/1*sZAO3DqaDnFg2aeEFm2jCA.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3116f1d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>What is a projection?</h3>\n",
    "    <h3>Definition:</h3>\n",
    "    <p>The projection of vector $A$ unto vector $B$ is equivalent to finding the horizontal component of vector $A$ if vector $B$ was the $x$-axis.</p>\n",
    "    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Dot_Product.svg/200px-Dot_Product.svg.png\"/>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af75df",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " <h3>Proof of the Formula for the Magnitude of a Projection: </h3>\n",
    "    <p>Looking at the image above, the magnitude of the projection is equivalent to $\\cos(\\theta) \\cdot |\\mathbf{A}|$. To find\n",
    "     $\\cos(\\theta)$, we can use the dot product formula $$\\mathbf{A} \\cdot \\mathbf{B} = |\\mathbf{A}| \\cdot |\\mathbf{B}| \\cdot \\cos(\\theta)$$\n",
    "     By dividing the magnitudes on both sides, we get\n",
    "      $$\\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{|\\mathbf{A}| \\cdot |\\mathbf{B}|}$$\n",
    "     Plugging this value for $\\cos(\\theta)$, we find that magnitude of the projection is \n",
    "        $$\\left\\lVert \\text{proj}_{\\mathbf{B}}(\\mathbf{A}) \\right\\rVert = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{|\\mathbf{B}|} \n",
    "$$\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eea58b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will set that distance as $C$. We can then create the equation $\\frac{\\mathbf{X} \\cdot \\mathbf{W}}{|\\mathbf{W}|}=C $ where it represents points on the decision boundary. Using the image above, $\\frac{\\mathbf{X} \\cdot \\mathbf{W}}{|\\mathbf{W}|}-C<0 $ when the point is yellow, and $\\frac{\\mathbf{X} \\cdot \\mathbf{W}}{|\\mathbf{W}|}-C>0 $ when the point is blue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9145b0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will simplify the equation to $y_{\\text{i}}(X \\cdot W+B)\\ge0$ where $B$ is the negative and scaled version of $C$. $y_{\\text{i}}$ is equal to $1$ when the point is positive and $-1$ when the point is negative. The blue points in the image above will be the positive points while the yellow points will be the negative sample. This wil simplify the equation without taking away from the utility of the decision equation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eab96bf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<h3>Why can you change the scaling of$\\frac{\\mathbf{X} \\cdot \\mathbf{W}}{|\\mathbf{W}|}$and $C$ without any problems?</h3>\n",
    "    <p>Because we only care about the negativity of the decision equation, it is fine if the scaling is different</p>\n",
    "    <h5>For example:</h5>\n",
    "    $X \\cdot W+B=-4$ and $\\frac{X \\cdot W}{2}+\\frac{B}{2}=-2$ both mean the points are in the negative sample despite the decision equation being scaled up, thus making the mathematical convenience of taking away $|W|$ more important.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59869c0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### In order to allow the SVM to generalize better, we want a margin between the two classes as seen in the image bellow. To create the margin, we change  $y_{\\text{i}}(X \\cdot W+B)\\ge0$ to  $y_{\\text{i}}(X \\cdot W+B)\\ge1$ where 1 represents the distance from the margin border to the decision boundary. This also means that the margin space is equal for both classes to make sure the classification is balanced. We also want the margin to be as big as possible to increase seperation between the two classes, allowing the SVM to handle unseen data better.\n",
    "\n",
    "<img width=\"300\" src=\"https://miro.medium.com/v2/resize:fit:1132/1*SgXnNjy8aXR-6ZwaPek0xg.png\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24666d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### How can you be sure the margin space is just $1$?\n",
    "##### Even though the margin space is likely to not just be $1$, it doesn't matter since $X \\cdot W+B$ will be scaled to correctly match margin width. The $1$ is just used for mathematical convenience.\n",
    "\n",
    "#### Play around with the graph below to understand what I mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2fdebf7",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2f7ed7c7df41158ff1690d1e473aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.0, description='m', max=5.0, min=-5.0), Output()), _dom_classes=('wi…"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interactive\n",
    "\n",
    "def plot_lines(m):\n",
    "    x = np.linspace(-10, 10, 100)\n",
    "    \n",
    "\n",
    "    y1 = -x  # x + y = 0\n",
    "    \n",
    "    epsilon = 1e-5\n",
    "    if abs(m) > epsilon:\n",
    "        y2 = (1 / m) - x  # m * (x + y) = 1\n",
    "        y3 = -(1 / m) - x  # m * (x + y) = -1\n",
    "    else:\n",
    "        y2 = np.zeros_like(x)\n",
    "        y3 = np.zeros_like(x)\n",
    "    \n",
    "    plt.plot(x, y1, '-r', label='x + y = 0')\n",
    "    plt.plot(x, y2, '-g', label=f'm * (x + y) = 1 (m={m:.2f})')\n",
    "    plt.plot(x, y3, '-b', label=f'm * (x + y) = -1 (m={m:.2f})')\n",
    "    \n",
    "    plt.title('Graphs of Equations')\n",
    "    plt.xlabel('x-axis')\n",
    "    plt.ylabel('y-axis')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(plot_lines, m=(-5, 5, 0.1))\n",
    "\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402bc2e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now that we have the SVM decision equation, we want to figure out how to maximize the margin. To do this, we will use support vectors which are the points closest to the decision boundary that will define the starting point of the margins.\n",
    "\n",
    "<img src=\"https://www.edureka.co/blog/wp-content/uploads/2019/11/svm-2.png\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085f5e8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Because the ideal support vectors will be on the margins of the decision lines, we can find the width of the margin by finding the vector that connects the two support vectors.\n",
    "\n",
    "### We find that vector by subtracting the support vector further from the origin by the other support vector as shown in the image below. We will call that vector $Z$.\n",
    "\n",
    "$$Z=x_2-x_1$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbc5949",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"https://i.stack.imgur.com/1bd4E.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c875ae24",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Because vector $W$ is perpendicular to the margins and decision line, we can equate the magnitude of the projection of $Z$ onto $W$ as the width of the margin.\n",
    "\n",
    " $$\\left\\lVert \\text{proj}_{\\mathbf{W}}(\\mathbf{Z}) \\right\\rVert = \\frac{\\mathbf{Z} \\cdot \\mathbf{W}}{|\\mathbf{W}|}$$\n",
    " $$\\frac{\\mathbf{Z} \\cdot \\mathbf{W}}{|\\mathbf{W}|}=\\frac{\\mathbf{(x_2-x_1)} \\cdot \\mathbf{W}}{|\\mathbf{W}|}=\\frac{\\mathbf{x_2} \\cdot \\mathbf{W}-\\mathbf{x_1} \\cdot  \\mathbf{W}}{|\\mathbf{W}|}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fe704d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using the decision equation, $y_i (W \\cdot x+b)=1$, assuming $x_1$ is in the negative class and $x_2$ is in the positive class:\n",
    "$$W \\cdot x_2+b=1$$\n",
    "Equation 2: $$W \\cdot x_2=1-b$$\n",
    "$$-1 \\cdot(W \\cdot x_1+b)=1$$\n",
    "$$W \\cdot x_1+b=-1$$\n",
    "Equation 3: $$ W \\cdot x_1=-1-b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598bf123",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Plug $W \\cdot x_1$ and $W \\cdot x_2$ into the equation for the magnitude of the projection to get:\n",
    "$$\\frac{1-b-(-1-b)}{|\\mathbf{W}|}$$\n",
    "$$\\frac{1-b+1+b)}{|\\mathbf{W}|}$$\n",
    "$$\\frac{2}{|\\mathbf{W}|}$$\n",
    "### Now that we have seen that the width of the margin created by the support vectors is $\\frac{2}{|\\mathbf{W}|}$, it is clear that in order to train the SVM model and find the optimal support vectors, we want to maximize the magnitude of vector $W$ such that the classifications of the training data are correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8c59e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will now explore the math behind calibrating vector $W$ to create the decision equation. \n",
    "### The Hinge Loss Function:\n",
    "\n",
    "$$L=max(0,1-(X \\cdot W+B))$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8f8cc0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How it works is that if the decision equation is at least $1$, the loss is $0$ since the datapoint has been correctly classified. If the decision equation computes a value less than $1$, the loss is $1-y_{\\text{i}}(X \\cdot W+B)$ since the lower the loss function's output gets, which means a less accurate classification, the bigger the loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af1e728",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### $J(\\lambda, w) = \\lambda \\cdot \\frac{1}{2} \\|w\\|^2 + \\max(0, 1 - y_{\\text{i}}\\cdot (w \\cdot x))$ will be used as the loss function. $\\lambda$ is a hyperparameter which determines how much you want $\\|w\\|^2$ to affect the loss function. Hyperparamaters are a useful tool to control how well the SVM generalizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8821909",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We will take the partial derivatives of the loss function with respect to $w$ and $b$ to figure out how much these variables should be calibrated to create the decision function. \n",
    "\n",
    "$$w=w-\\alpha \\cdot dw$$\n",
    "$$b=b-\\alpha \\cdot db$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a95f71",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The $dw$ and $db$ change depending on the value of the decision equation as shown by the max function in the loss function\n",
    "\n",
    "#### If decision equation, $y_{\\text{i}}\\cdot (w \\cdot x)$, is greater than $1$, the loss function is $\\lambda \\cdot \\frac{1}{2} \\|w\\|^2$ which means the derivative with respect to $dw$ is $2\\lambda w$ and the derivative with respect to $db$ is $0$. If the decision equation is less than $1$, the loss function is $\\lambda \\cdot \\frac{1}{2} \\|w\\|^2+ 1 - y_{\\text{i}}\\cdot (w \\cdot x)$. This means the derivative with respect to $dw$ is $2\\lambda w-y_{\\text{i}}\\cdot x$. The derivative with respect to $db$ is $y_{\\text{i}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8646419e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The final result:\n",
    "\n",
    "#### When the decision equation returns a value greater or equal to $1$ (the classification of the training data was correct):\n",
    "$$w=w-\\alpha \\cdot 2\\lambda w$$\n",
    "$$b=b$$\n",
    "\n",
    "#### When the decision equation returns a value less than $1$ (the classification of the training data was incorrect):\n",
    "$$w=w-\\alpha \\cdot (2\\lambda w-y_{\\text{i}}\\cdot x)$$\n",
    "$$b=b-\\alpha \\cdot y_{\\text{i}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7c74d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient Descent\n",
    "<img src=\"data:image/jpeg;base64,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\"/>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b280280",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why are we subtracting $w$ and $b$ by $dw$ and $db$?\n",
    "\n",
    "### Looking at the image above, we see a graph of how the loss function with $w$ as $x$, $b$ as $y$ and $J(\\lambda,w)$  $z$ if $w$ and $b$ were one dimensional. The goal is to minimize the loss or how much the decision decision is wrong, so we want to reach the minimum. If loss function has a higher value, which means a point with a higher $z$ value in the graph, the partial derivatives will be higher, resulting in a more drastic descent to the bottom. Once it reaches the bottom, the partial derivatives will start to lessen and mingle around zero.Thus we end up with the minimum!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd6fb7c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing The SVM\n",
    "\n",
    "### Open up a code editor like VSCode and we will create an SVM from scratch!\n",
    "\n",
    "#### We will\n",
    "\n",
    "1. Import numpy to work with matrices and arrays.\n",
    "2. Import train_test_split to split data into training and testing data.\n",
    "3. Import matplotlib.pyplot to graph the data points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6930995c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02670b72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Define an SVM class and create the class constructor. \n",
    "2. Define self, learning rate, lambda, and the number of iterations as parameters as shown below.\n",
    "3. We will set the self variables to the parameter values.\n",
    "4. Define vector $w$ as “None” along with $b$.\n",
    "5. self.color will be the help differentiate different classes when graphing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88490b2a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d1115",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Define a fit function in SVM with self, the input data, and class identifier as parameters.\n",
    "2. $X$.shape gets the dimension of the array. \n",
    "3. The number of features is the length of each input array. n_samples is the number of input arrays.\n",
    "4. y_ is the class identifiers ($-1$ or $1$) assigned to each input array, so y_ will have the same length as n_samples.\n",
    "5. Vector $w$ will have the same number of dimensions as the input count, and the value of each of its dimensions will be set to $0$.\n",
    "6. $b$ will also be set to $0$ as the starting value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9a5512",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63a4a38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Create a for-loop with n_iters as the looping variable\n",
    "2. n_iters defines how many times you want to fit vector $w$.\n",
    "3. We then iterate through the input data.\n",
    "4. we use enumerate to allow the for-loop to access the index of each input array and the array itself.\n",
    "5. idx is the index of the input array, and x_i is the individual input array.\n",
    "6. The code in each iteration uses the Hinge Loss function and Regularization concepts.\n",
    "7. Basically, vector w and b will be altered differently depending on how well the decision function works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ab1f82",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c2366",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Define the predict function with self and the prediction inputs as its parameters.\n",
    "2. The results will store the classification of each prediction input.\n",
    "3. Iterate through each input array, and if plugging the input array into the decision function nets a negative sign, -1 is appended to results. If else, 1 is appended to results.\n",
    "4. The results array is returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a3ce6",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        \n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f5d0ac",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Define visualize with self, the training inputs, the training data classifications, and the predictions and their predicted classes as parameters.\n",
    "2. Define a plot figure, which will contain the plot elements.\n",
    "3. Define a subplot in the figure that allows the decision and margin lines to be plotted next to the input and prediction points.\n",
    "4. Enumerate x to be able to iterate through the input arrays and get their indexes.\n",
    "5. Plot the inputs as dots, and set the color based on the classification.\n",
    "6. Scatter the prediction inputs the same way except their marker will be an ‘x’ and they will have a larger size.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c135c078",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results\n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb611ff0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Define the hyperplane function with $z$, vector $w$, $b$, and the offset value as the parameters. This function will graph the decision boundary and the margin lines.\n",
    "2. To find the linear function of the decision line, we can use the decision function. Let $x_2$ be the y-value of our graph:\n",
    "      $$w \\cdot x+b=0$$\n",
    "      $$[w_1,w_2] \\cdot [x_1, x_2]^T+b=0$$\n",
    "      $$w_1 \\cdot x_1+w_2 \\cdot x_2+b=0$$\n",
    "      $$w_2 \\cdot x_2=-b-w_1 \\cdot x_1$$\n",
    "      $$x_2=\\frac{-b-w_1 \\cdot x_1}{w_2}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f641a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. The reason there is only $x_1$ and $x_2$ is because I want to graph the decision function and its boundaries which is only possible if there are only two dimensions to the input.\n",
    "2. We get the maximum $x_1$ value in the dataset and the minimum value to make sure all the other datapoints are shown in the graph. This is because the x-values of the points used to create the graph dictate the x-window of the graph.\n",
    "3. We are basically getting the dot product of $w$ and $x$ and isolate the $x_2$ value to get the corresponding y-values on the decision line.\n",
    "4. If you want to find the linear function of the hard margin, set the decision equation to 1 or -1, and isolate $x_2$ from the dot product. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340011a6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Let the offset value ($1$ or $-1$) be $y_i$:\n",
    "$$w \\cdot x+b=y_i$$\n",
    "      $$[w_1,w_2] \\cdot [x_1, x_2]^T+b=y_i$$\n",
    "      $$w_1 \\cdot x_1+w_2 \\cdot x_2+b=y_i$$\n",
    "      $$w_2 \\cdot x_2=y_i-b-w_1 \\cdot x_1$$\n",
    "      $$x_2=\\frac{y_i-b-w_1 \\cdot x_1}{w_2}$$\n",
    "2. Replace $y_i$ with variable $offset$, which equals $0$,$1$, and $-1$, depending on if you want to find the $y$ values of points on the decision line or the hard margins. This is how you get the hyperplane function in the code below.\n",
    "3. The hyperplane function calls are used to get the y-values of the left-most and right-most points on the decision line and hard margins.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8b2aef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results \n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "        def hyperplane(z,w,b,offset):\n",
    "            return (-w[0]*z-b+offset)/w[1]\n",
    "        x0_1=np.amin(x[:,0])\n",
    "        x0_2=np.amax(x[:,0])\n",
    "        x1_1=hyperplane(x0_1,self.w,self.b,0)\n",
    "        x1_2=hyperplane(x0_2,self.w,self.b,0)\n",
    "        x2_1=hyperplane(x0_1,self.w,self.b,-1)\n",
    "        x2_2=hyperplane(x0_2,self.w,self.b,-1)\n",
    "        x3_1=hyperplane(x0_1,self.w,self.b,1)\n",
    "        x3_2=hyperplane(x0_2,self.w,self.b,1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e76971",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "1. Plot the lines. \n",
    "2. “y- -” creates a dashed line while “k” is a smooth line\n",
    "3. x1_min and x1_max are the least and greatest y-values in the training input data.\n",
    "4. ax.set_ylim sets the y-window of the graph or the range of y-values that should be shown.\n",
    "5. Show the plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f02a0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results \n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "        def hyperplane(z,w,b,offset):\n",
    "            return (-w[0]*z-b+offset)/w[1]\n",
    "        x0_1=np.amin(x[:,0])\n",
    "        x0_2=np.amax(x[:,0])\n",
    "        x1_1=hyperplane(x0_1,self.w,self.b,0)\n",
    "        x1_2=hyperplane(x0_2,self.w,self.b,0)\n",
    "        x2_1=hyperplane(x0_1,self.w,self.b,-1)\n",
    "        x2_2=hyperplane(x0_2,self.w,self.b,-1)\n",
    "        x3_1=hyperplane(x0_1,self.w,self.b,1)\n",
    "        x3_2=hyperplane(x0_2,self.w,self.b,1)\n",
    "        ax.plot([x0_1,x0_2],[x1_1,x1_2],\"y--\")\n",
    "        ax.plot([x0_1,x0_2],[x2_1,x2_2],\"k\")\n",
    "        ax.plot([x0_1,x0_2],[x3_1,x3_2],\"k\")\n",
    "        x1_min = np.amin(x[:, 1])\n",
    "        x1_max = np.amax(x[:, 1])\n",
    "        ax.set_ylim([x1_min - 3, x1_max + 3])\n",
    "        plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58c2515",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We can now train an SVM model around a dataset.\n",
    "\n",
    "#### 1. Create a $3$-dimensional array called $x$ where the dimensions are the number of datapoints, the x-value of the datapoint, and the y-value of the datapoint.\n",
    "#### 2. Create a $1$-dimensional array called $y$ where each value is either a $1$ or $-1$ to signify the classification of the point.\n",
    "#### 3. Create the dataset yourself, but you can use the one I created. \n",
    "#### 4. Make sure the first dimensions of $x$ and $y$ have the same length.\n",
    "#### 5. Make sure the arrays are numpy arrays as shown in the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad594aa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results \n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "        def hyperplane(z,w,b,offset):\n",
    "            return (-w[0]*z-b+offset)/w[1]\n",
    "        x0_1=np.amin(x[:,0])\n",
    "        x0_2=np.amax(x[:,0])\n",
    "        x1_1=hyperplane(x0_1,self.w,self.b,0)\n",
    "        x1_2=hyperplane(x0_2,self.w,self.b,0)\n",
    "        x2_1=hyperplane(x0_1,self.w,self.b,-1)\n",
    "        x2_2=hyperplane(x0_2,self.w,self.b,-1)\n",
    "        x3_1=hyperplane(x0_1,self.w,self.b,1)\n",
    "        x3_2=hyperplane(x0_2,self.w,self.b,1)\n",
    "        ax.plot([x0_1,x0_2],[x1_1,x1_2],\"y--\")\n",
    "        ax.plot([x0_1,x0_2],[x2_1,x2_2],\"k\")\n",
    "        ax.plot([x0_1,x0_2],[x3_1,x3_2],\"k\")\n",
    "        x1_min = np.amin(x[:, 1])\n",
    "        x1_max = np.amax(x[:, 1])\n",
    "        ax.set_ylim([x1_min - 3, x1_max + 3])\n",
    "        plt.show()\n",
    "x=np.array([[1,-3],[1,8],[6,7],[8,9],[11,10],[1,2],[0,3],[-1,4],[2,2],[16,7],[-3,-2],[17,10],[5,2],[3,-10],[-8,-8],[3,2],[12,14],[7,8],[23,11],[9,11],[-2,4],[-10,2],[3,3],[1,3],[6,6],[6,9],[7,9],[8,10]])\n",
    "y=np.array([-1,1,1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1,1,1])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3137bc8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 1. Split the dataset into training and testing data, where the test_size indicates how much of the dataset you want to use to test your SVM model\n",
    "#### 2. Create the SVM object \n",
    "#### 3. Fit the SVM model around the training data\n",
    "#### 4. Used the trained model to predict the classifications for the testing data\n",
    "#### 5. Create an \"accuracy\" function. which will take the actual classifications and predicted classifications to calculate accuracy of the model\n",
    "#### 6. Accuracy is basically the proportion of classifications ($1$ or $-1$) that are correct with the total amount of classifications\n",
    "#### 7. Print out the predictions and accuracy if you want\n",
    "#### 8. Visualize your data and the SVM classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb898ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Full Code With Implementation:\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results \n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "        def hyperplane(z,w,b,offset):\n",
    "            return (-w[0]*z-b+offset)/w[1]\n",
    "        x0_1=np.amin(x[:,0])\n",
    "        x0_2=np.amax(x[:,0])\n",
    "        x1_1=hyperplane(x0_1,self.w,self.b,0)\n",
    "        x1_2=hyperplane(x0_2,self.w,self.b,0)\n",
    "        x2_1=hyperplane(x0_1,self.w,self.b,-1)\n",
    "        x2_2=hyperplane(x0_2,self.w,self.b,-1)\n",
    "        x3_1=hyperplane(x0_1,self.w,self.b,1)\n",
    "        x3_2=hyperplane(x0_2,self.w,self.b,1)\n",
    "        ax.plot([x0_1,x0_2],[x1_1,x1_2],\"y--\")\n",
    "        ax.plot([x0_1,x0_2],[x2_1,x2_2],\"k\")\n",
    "        ax.plot([x0_1,x0_2],[x3_1,x3_2],\"k\")\n",
    "        x1_min = np.amin(x[:, 1])\n",
    "        x1_max = np.amax(x[:, 1])\n",
    "        ax.set_ylim([x1_min - 3, x1_max + 3])\n",
    "        plt.show()\n",
    "x=np.array([[1,-3],[1,8],[6,7],[8,9],[11,10],[1,2],[0,3],[-1,4],[2,2],[16,7],[-3,-2],[17,10],[5,2],[3,-10],[-8,-8],[3,2],[12,14],[7,8],[23,11],[9,11],[-2,4],[-10,2],[3,3],[1,3],[6,6],[6,9],[7,9],[8,10]])\n",
    "y=np.array([-1,1,1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1,1,1])\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=SVM()\n",
    "clf.fit(x_train,y_train)\n",
    "predictions=clf.predict(x_test)\n",
    "def accuracy(true,predict):\n",
    "    accurate=np.sum(true==predict)/len(true)\n",
    "    return accurate\n",
    "\n",
    "print(predictions)\n",
    "print(accuracy(y_test,clf.predict(x_test)))\n",
    "\n",
    "clf.visualize(x_train,y_train,x_test,predictions)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cab7ca4",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, -1.0, -1.0, 1.0, 1.0, -1.0]\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "class SVM:\n",
    "    def __init__(self,learning_rate=0.001,lambda_param=0.01,n_iters=10000):\n",
    "        self.lr=learning_rate\n",
    "        self.lambda_param=lambda_param\n",
    "        self.n_iters=n_iters\n",
    "        self.w=None\n",
    "        self.b=None\n",
    "        self.color={1:'red',-1:'blue'}\n",
    "    def fit(self,x,y):\n",
    "        n_samples,n_features=x.shape\n",
    "        y_=np.where(y<=0,-1,1)\n",
    "        self.w=np.zeros(n_features)\n",
    "        self.b=0\n",
    "        for _ in range(self.n_iters):\n",
    "            for idx,x_i in enumerate(x):\n",
    "                if(y_[idx]*(np.dot(x_i,self.w)+self.b)>=1):\n",
    "                    self.w-=self.lr*2*self.lambda_param*self.w\n",
    "                else:\n",
    "                    self.w-=self.lr*(2*self.lambda_param*self.w-np.dot(y_[idx],x_i))\n",
    "                    self.b+=self.lr*y_[idx]\n",
    "    def predict(self,x):\n",
    "        results=[]\n",
    "        for x_ in x:\n",
    "            prediction=np.dot(self.w,x_)+self.b\n",
    "            results.append(np.sign(prediction))\n",
    "        return results \n",
    "    def visualize(self,x,y,predictions,predictY):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(1,1,1)\n",
    "        [plt.scatter(x_[0],x_[1],s=100,color=self.color[y[h]]) for h,x_ in enumerate(x)]\n",
    "        \n",
    "        [plt.scatter(x_[0],x_[1],marker='x',s=150,color=self.color[predictY[h]]) for h,x_ in enumerate(predictions)]\n",
    "        def hyperplane(z,w,b,offset):\n",
    "            return (-w[0]*z-b+offset)/w[1]\n",
    "        x0_1=np.amin(x[:,0])\n",
    "        x0_2=np.amax(x[:,0])\n",
    "        x1_1=hyperplane(x0_1,self.w,self.b,0)\n",
    "        x1_2=hyperplane(x0_2,self.w,self.b,0)\n",
    "        x2_1=hyperplane(x0_1,self.w,self.b,-1)\n",
    "        x2_2=hyperplane(x0_2,self.w,self.b,-1)\n",
    "        x3_1=hyperplane(x0_1,self.w,self.b,1)\n",
    "        x3_2=hyperplane(x0_2,self.w,self.b,1)\n",
    "        ax.plot([x0_1,x0_2],[x1_1,x1_2],\"y--\")\n",
    "        ax.plot([x0_1,x0_2],[x2_1,x2_2],\"k\")\n",
    "        ax.plot([x0_1,x0_2],[x3_1,x3_2],\"k\")\n",
    "        x1_min = np.amin(x[:, 1])\n",
    "        x1_max = np.amax(x[:, 1])\n",
    "        ax.set_ylim([x1_min - 3, x1_max + 3])\n",
    "        plt.show()\n",
    "x=np.array([[1,-3],[1,8],[6,7],[8,9],[11,10],[1,2],[0,3],[-1,4],[2,2],[16,7],[-3,-2],[17,10],[5,2],[3,-10],[-8,-8],[3,2],[12,14],[7,8],[23,11],[9,11],[-2,4],[-10,2],[3,3],[1,3],[6,6],[6,9],[7,9],[8,10]])\n",
    "y=np.array([-1,1,1,1,1,-1,-1,-1,-1,1,-1,1,-1,-1,-1,-1,1,1,1,1,-1,-1,-1,-1,1,1,1,1])\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
    "\n",
    "clf=SVM()\n",
    "clf.fit(x_train,y_train)\n",
    "predictions=clf.predict(x_test)\n",
    "def accuracy(true,predict):\n",
    "    accurate=np.sum(true==predict)/len(true)\n",
    "    return accurate\n",
    "\n",
    "print(predictions)\n",
    "print(accuracy(y_test,clf.predict(x_test)))\n",
    "\n",
    "clf.visualize(x_train,y_train,x_test,predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f727399e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Experiment!\n",
    "#### Create random datasets to see how the SVM draws the decision boundary\n",
    "#### Try creating datasets that might not seem linearly separable, and see how SVM does there.\n",
    "#### Experiment with the lambda, training rate, and n_iter values, which can be set during the creation of the SVM object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060dbd69",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Final Words\n",
    "#### Now that you know how the basic SVM algorithm works, you can use this machine learning algorithm into your projects to classify new data based on a dataset.\n",
    "#### For example, it can be used to handwriting recognition apps, gene classification, and many more classification problems. \n",
    "#### SVM is powerful in that once you fit the data and get the decision function, predictions can be made as easily as plugging in the input and seeing if the decision function outputs a negative or positive value.\n",
    "#### If you want to use SVM, I would recommend using sklearn’s algorithm, as it should have OVO, OVR, kernels, and soft margin capabilities, while the algorithm we wrote today was only to help you understand SVM.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50512a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### More Resources\n",
    "#### Understanding sklearn’s SVM: \n",
    "#### https://scikit-learn.org/stable/modules/svm.html\n",
    "#### Further Your Understanding of SVM’s Potential:\n",
    "#### https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/#:~:text=%E2%80%9CSupport%20Vector%20Machine%E2%80%9D%20\n",
    "#### Kernels:\n",
    "#### https://www.geeksforgeeks.org/major-kernel-functions-in-support-vector-machine-svm/#:~:text=%E2%80%9CKernel%E2%80%9D%20is%20used%20due%20to,higher%20number%20of%20dimension%20spaces.\n",
    "#### Soft Margin: \n",
    "#### https://towardsdatascience.com/support-vector-machines-soft-margin-formulation-and-kernel-trick-4c9729dc8efe?gi=651bfa1b4111\n",
    "#### Multi-class Classification: \n",
    "#### https://www.baeldung.com/cs/svm-multiclass-classification\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
